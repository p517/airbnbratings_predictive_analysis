x
paste("Today is", date())
cat("Today is", date())
tolower(x)
toupper
toupper(x)
is.character(x)
is.character(20.2)
is.character(as.character(20.2))
as.numeric(x)
x <- as.Date("25-01-29", format ="%y-%m-%d")
x
as.numeric(x)
y <- as.Date("01/25/2023", "%m/ %d /%Y")
y
x-y
x
z <- as.Date("jan211960", "%b%d%y")
z
as.numeric(z)
x <- (2 <=3)
x
y <- "data" < "stats"
y
x | y
x
y
x & y
!y
v1 <- c("R", "Excel", "SAS", "Excel")
v1 <- c(1,3,2,1,5)
v1 <- c("R", "Excel", "SAS", "Excel")
v2 <- c(1,3,2,1,5)
v <- 1:10
v
v <- 10:1
v
seq(from=1, to=6, length=3)
seq(from=1, to=3, by=3)
rep(7,3)
rep(1:2, 3)
rep(1:2, each 3)
rep(1:2, each=3)
rep(1:4, c(2, 1, 2, 1))
rep(1:4, c(2, 1, 2, 1))
x <- 1:10
x <= 5
x <= 5
x/4
x*3
x %% 2
x %/%2
x <- 1:10
y <- -5:4
x <- 1:10
x
4
y
x + c(1,2)
x + rep(c(1,2), 5)
x
x <- 10:1
x
x[1]
x[1:2]
x[c(1,4)]
x[ x<=3 | x>=7]
x[-c(1,3)]
x[length(x)]
v1 <- c(4, 0.36, 81, 2)
names(v1) <- c("a","b","c","d")
v1[2]
v1["b"]
v1[1] <- 10
v1[5] <- 5
v1[7] <- 7
v1
names(v1)[5:7] <- c("e", "f", "g")
v1
v2 <- c(c(1,2,3), c(4,5,6))
v2
# (5.9) factor vectors #
education <- c("High School", "College", "Masters", "Doctorate", "College", "Masters")
education_factor <- as.factor(education)
education_factor
as.numeric(education_factor)
education_factor <- factor(x = education,
levels = c("High School", "College", "Masters", "Doctorate"),
ordered = TRUE)
z <- c(1, 2, NA, 8, 3, NA, 3)
z
is.na(z)
z <- c(1, NULL,3)
z
education <- c("High School", "College", "Masters", "Doctorate", "College", "Masters")
education_factor <- as.factor(education)
education_factor
as.numeric(education_factor)
education_factor <- factor(x = education,
levels = c("High School", "College", "Masters", "Doctorate"),
ordered = TRUE)
rsw <- read.csv("roc_sep_wx1.csv", stringsAsFactors = FALSE)
str(rsw)
setwd("/Users/ShujingSun/Desktop/Teaching/")  # mac
# Define lambda
lambda <- 2
# Probability of zero requests for one operator
p_zero <- dpois(0, lambda)
# Probability of more than zero requests
p_more_than_zero <- 1 - p_zero
# Calculate the required probabilities
# Exactly 2 operators receive zero requests
p_exactly_2 <- choose(3, 2) * (p_zero^2) * (p_more_than_zero)
# Exactly 3 operators receive zero requests
p_exactly_3 <- (p_zero^3)
# At least 2 operators receive zero requests
p_at_least_2 <- p_exactly_2 + p_exactly_3
# Display the result
p_at_least_2
fit.small = rpart(churn ~ .,
data=cellco.train,
control=rpart.control(xval=10, minsplit=50, cp=0.0))
fit.small <- rpart(churn ~ ., data=cellco.train, control=rpart.control(xval=10, minsplit=50, cp=0.0))
install.packages("rpart")
fit.small <- rpart(churn ~ ., data=cellco.train, control=rpart.control(xval=10, minsplit=50, cp=0.0))
fit.small <- rpart(churn ~ ., data=cellco.train, control=rpart.control(xval=10, minsplit=50, cp=0.0))
library(rpart)
# notice the rsw data.frame in the environment window
# you may check the data structure by using str()
str(rsw)
fit.small <- rpart(churn ~ ., data=cellco.train, control=rpart.control(xval=10, minsplit=50, cp=0.0))
bestcp <- fit.big$cptable[which.min(fit.big$cptable[,"xerror"]),"CP"]
# Part-f
tpr <- 0.3254438  # True Positive Rate
fpr <- 0.04484305 # False Positive Rate
likely_purchasers <- 200  # 10% of 2,000 customers
net_profit_per_cd <- 40   # NPV per CD ($50) minus cost per contact ($10)
cost_false_positives <- 18000  # Cost of contacting 1,800 customers who do not purchase a CD
# Calculate expected profit
expected_profit <- (tpr * likely_purchasers * net_profit_per_cd) - (fpr * cost_false_positives)
expected_profi
tpr <- 0.3254438  # True Positive Rate
fpr <- 0.04484305 # False Positive Rate
likely_purchasers <- 200  # 10% of 2,000 customers
net_profit_per_cd <- 40   # NPV per CD ($50) minus cost per contact ($10)
cost_false_positives <- 18000  # Cost of contacting 1,800 customers who do not purchase a CD
# Calculate expected profit
expected_profit <- (tpr * likely_purchasers * net_profit_per_cd) - (fpr * cost_false_positives)
expected_profit
qnorm(0.95)
qnorm(0.975)
qnorm(1-0.05)
qnorm(1-0.005)
qnorm(1-0.025)
x<-mean(9.0,8.6,9.2,8.4,8.1,9.5,9.3,8.5,9.0,9.4)
x
x
sd(x)
var(x)
x<-c(mean(9.0,8.6,9.2,8.4,8.1,9.5,9.3,8.5,9.0,9.4))
x
y<-var(9.0,8.6,9.2,8.4,8.1,9.5,9.3,8.5,9.0,9.4)
y<-c(var(9.0,8.6,9.2,8.4,8.1,9.5,9.3,8.5,9.0,9.4))
y<-var(c(9.0,8.6,9.2,8.4,8.1,9.5,9.3,8.5,9.0,9.4))
y
sd(y)
sqrt( 0.2244444)
qt(0.025,9,lower.tail=FALSE)
qt(0.05,9,lower.tail=FALSE)
sd(40.6)
sqrt(40.6)
mileage <- c(38, 42, 40, 39, 44, 37, 39, 45, 40, 42, 38, 39, 44, 41, 42)
sample_mean <- mean(mileage)
sample_sd <- sd(mileage)
sample_sd
qt(0.9,14,lower.tail=FALSE)
qt(0.05,lower.tail=FALSE)
qt(0.05,14,lower.tail=FALSE)
qnorm(0.025)
qnorm(1-0.025)
qnorm(0.01)
qnorm(0.01, lower.tail=FALSE)
qnorm(1-0.01)
qnorm(1-0.01)
1-pnorm(2.5)
qnorm(1-0.05)
qnorm(1-0.1)
1-pnorm(7.889)
1-pnorm(-1.57)
pnorm(-1.57)
pnorm(-1.53)
pnorm(1.325)
pnorm(1-1.325)
1-pnorm(2.03)
qt(0.05,7)
qt(0.05,5)
1-pnorm(2.03)
qt(0.01,19, lower.tail=false)
qt(0.01,19, lower.tail=FALSE)
pnorm(1.714)
qnorm(1-0.02)
qnorm(1-0.01)
1-0.9
0.1/2
1-pnorm(0.05)
pnorm(1-0.05)
qnorm(1-0.05)
1-0.95
0.05/2
qnorm(1-0.025)
qnorm(0.05)
1-qnorm(0.05)
qnorm(1-0.05)
1-qnorm(1.581)
1-pnorm(1.581)
pnorm(1-0.05)
1pnorm(0.05)
1-pnorm(0.05)
qnorm(1-0.05)
sqrt(40)
1.2/6.324
0.1897*0.005
10.4+0.0009485
10.4-0.0009485
qnorm(1-0.005)
qnorm(1-0.005)
c  <- mean(9, 8.6, 9.2, 8.4, 8.1, 9.5, 9.3, 8.5, 9, 9.4)
c
sd(c)
mean <- c(9, 8.6, 9.2, 8.4, 8.1, 9.5, 9.3, 8.5, 9, 9.4)
mean
sd(mean)
1-qt(0.025, 9)
1-qt(0.025, 9, lower.tail=FALSE)
qt(0.025, 9, lower.tail=FALSE)
pnorm(0,05)
pnorm(0.05)
qnorm(1-0.025)
qnorm(0.01)
1-qnorm(0.01)
1-pnorm(0.01)
q(1-0.01)
qnorm(1-0.01)
pnorm(0.01)
1-pnorm(0.01)
1-pnorm(2.49)
exp(0.37)
exp(0.51)
p_value <- pf(3.054, df1 = 2, df2 = 13, lower.tail = FALSE)
p_value
qnorm(1-0.01)
qt(0.01, 19, lower.tail=FALSE)
x = c(102, 111, 109, 105)
x
x/4
x <- c(102, 111, 109, 105)
mean(x)
y <- c(125, 103, 121, 118)
mean(y)
sd(x)
sd(y)
pnorm(-1.92)
qnorm(-1.92)
1-qnorm(-1.92)
1-pnorm(-1.92)
1-qt(1.1714, 99)
qt(1.1714, 99)
1-tt(1.1714, 99, )
1-pt(1.1714, 99)
1-pt(1.1714, df = 99)
qnorm(1-0.01)
x <- c(100,125,135,128,140,142,128,137,156,142,108)
mean(x)
y <- c(95,87,98,75,110,103,85,91,101,102)
mean(y)
sd(131)
sd(x)
sd(y)
qnorm(1-0.05)
qnorm(1-0.05)
qnorm(1-0.05)
pnorm(0.05)
qnorm(0.05)
qnorm(0.005)
qnorm(1-0.005)
y <- c(9,8.6,9.2,8.4,8.1,9.5,9.3,8.5,9,9.4)
mean(y)
sd(y)
qnorm(1-0.025)
1-qt(0.025, 9)
qt(0.025, 9, lower.tail = FALSE)
y <- c(38,42,40,39,44,37,39,45,40,42,38,39,44,41,42)
mean(y)
sd(y)
qt(0.05,14,lower.tail=FALSE)
pnorm(0.1)
qnorm(0.01)
qnorm(1-0.01)
qt(0.1,14,lower.tail=FALSE)
qnorm(1-0.025)
qnorm(1-0.01)
qnorm(1-0.05)
1-pnorm(2.5)
qnorm(0.05)
qnorm(0.01)
1-qnorm(0.01)
qnorm(1-0.01)
qnorm(0.01)
qnorm(1-0.05)
qnorm(0.1)
qnorm(1-0.1)
1-pnorm(1.53)
2*0.06300836
qnorm(0.05)
qt(0.05,7,lower.tail=FALSE)
qt(2.47,11,lower.tail=FALSE)
1-pt(2.47,11,lower.tail=FALSE)
qt(2.47,11)
1-pt(2.47,11)
qt(0.05,11,lower.tail=FALSE)
qt(0.05,11,lower.tail=FALSE)
x <- c(100,125,135,128,140,142,128,137,156,142,108)
y <- c(95,87,98,75,110,103,85,91,101,102)
mean(x)
mean(y)
sd(x)
sd(y)
qnorm(1-0.05)
1 - pt(1.714, df = 99)
1 - qt(1.714, df = 99)
1-pnorm(1.714)
qnorm(1-0.05)
qt(0.05, 9, lower.tail=FALSE)
qt(0.05, 8, lower.tail=FALSE)
# Given values
sample_mean <- 0.275
std_dev <- 0.001
n <- 60
z_score <- qnorm(0.95)
# Standard Error
SE <- std_dev / sqrt(n)
# Margin of Error
ME <- z_score * SE
# Confidence Interval
lower_bound <- sample_mean - ME
upper_bound <- sample_mean + ME
# Print the result
cat("90% Confidence Interval: (", round(lower_bound, 4), ",", round(upper_bound, 4), ")\n")
90% Confidence Interval: ( 0.2748 , 0.2752 )
sample_mean <- 0.275
std_dev <- 0.001
n <- 60
z_score <- qnorm(0.95)
SE <- std_dev / sqrt(n)
ME <- z_score * SE
lower_bound <- sample_mean - ME
upper_bound <- sample_mean + ME
cat("90% Confidence Interval: (", round(lower_bound, 4), ",", round(upper_bound, 4), ")\n")
Question - 2
x <- 70
n <- 100
p <- x / n
z <- qnorm(0.975)
SE <- sqrt((p * (1 - p)) / n)
ME <- z * SE
lower_bound <- p - ME
upper_bound <- p + ME
cat("95% Confidence Interval: (", round(lower_bound, 4), ",", round(upper_bound, 4), ")\n")
x_bar <- 405
mu_0 <- 400
s <- 100
n <- 1000
z <- (x_bar - mu_0) / (s / sqrt(n))
z
z_alpha <- qnorm(0.95)
z_alpha
p_value <- 1 - pnorm(z)
p_value
measurements <- c(
20.10, 19.75, 20.20, 20.15, 19.90, 20.00, 19.65, 19.92, 19.80, 20.13,
19.98, 20.05, 20.20, 20.23, 20.31, 20.01, 20.49, 19.99, 20.13, 20.18,
20.03, 19.87, 19.93, 20.11, 20.22, 19.84, 20.12, 20.24, 20.03, 20.08,
20.00, 20.11, 20.99, 20.33, 20.11, 19.89, 20.32, 19.76, 20.05, 19.97,
20.05, 19.85, 19.87, 19.67, 20.06, 19.95, 20.09, 20.10, 19.90, 19.73
)
lower_limit <- 20.0 - 0.3
upper_limit <- 20.0 + 0.3
nonconforming <- sum(measurements < lower_limit | measurements > upper_limit)
n <- length(measurements)
p_hat <- nonconforming / n
nonconforming <- sum(measurements < lower_limit | measurements > upper_limit)
n <- length(measurements)
p_har <- nonconforming / n
nonconforming <- sum(measurements < lower_limit | measurements > upper_limit)
n <- length(measurements)
p_bar <- nonconforming / n
z_90 <- qnorm(0.95)
SE <- sqrt((p_bar * (1 - p_bar)) / n)
ME_90 <- z_90 * SE
CI_90 <- c(p_bar - ME_90, p_bar + ME_90)
cat("90% CI for proportion of nonconforming items: (", round(CI_90[1], 4), ",", round(CI_90[2], 4), ")\n")
z_95 <- qnorm(0.975)
ME_95 <- z_95 * SE
CI_95 <- c(p_bar - ME_95, p_hat + ME_95)
cat("95% CI for proportion of nonconforming items: (", round(CI_95[1], 4), ",", round(CI_95[2], 4), ")\n")
p0 <- 0.13
z_test <- (p_hat - p0) / sqrt((p0 * (1 - p0)) / n)
p_value <- 1 - pnorm(z_test)
cat("Z statistic:", round(z_test, 4), "\n")
cat("P-value:", round(p_value, 4), "\n")
if (p_value < 0.05) {
cat("Conclusion: Reject H0. Proportion of nonconforming items is significantly greater than 13%.\n")
} else {
cat("Conclusion: Fail to reject H0. Not enough evidence to say proportion is greater than 13%.\n")
}
sample_mean <- 0.275
std_dev <- 0.001
n <- 60
z_score <- qnorm(0.95)
SE <- std_dev / sqrt(n)
ME <- z_score * SE
lower_bound <- sample_mean - ME
upper_bound <- sample_mean + ME
lower_bound
upper_bound
x <- 70
n <- 100
p <- x / n
z <- qnorm(0.975)
SE <- sqrt((p * (1 - p)) / n)
ME <- z * SE
lower_bound <- p - ME
upper_bound <- p + ME
lower_bound
upper_bound
x_bar <- 405
mu_0 <- 400
s <- 100
n <- 1000
alpha <- 0.05
z <- (x_bar - mu_0) / (s / sqrt(n))
z
p_value <- 1 - pnorm(z)
p_value
z_90 <- qnorm(0.95)
SE <- sqrt((p_hat * (1 - p_hat)) / n)
ME_90 <- z_90 * SE
CI_90 <- c(p_hat - ME_90, p_hat + ME_90)
C_90
CI_90
lower_limit <- 20.0 - 0.3
upper_limit <- 20.0 + 0.3
nonconforming <- sum(measurements < lower_limit | measurements > upper_limit)
n <- length(measurements)
p_bar <- nonconforming / n
z_90 <- qnorm(0.95)
SE <- sqrt((p_hat * (1 - p_hat)) / n)
ME_90 <- z_90 * SE
CI_90 <- c(p_hat - ME_90, p_hat + ME_90)
CI_90
z_95 <- qnorm(0.975)
ME_95 <- z_95 * SE
CI_95 <- c(p_hat - ME_95, p_hat + ME_95)
C_95
CI_95
p0 <- 0.13
z_test <- (p_hat - p0) / sqrt((p0 * (1 - p0)) / n)
p_value <- 1 - pnorm(z_test)
cat("Z statistic:", round(z_test, 4), "\n")
cat("P-value:", round(p_value, 4), "\n")
if (p_value < 0.05) {
cat("Conclusion: Reject H0. Proportion of nonconforming items is significantly greater than 13%.\n")
} else {
cat("Conclusion: Fail to reject H0. Not enough evidence to say proportion is greater than 13%.\n")
}
Output: Conclusion: Fail to reject H0. Not enough evidence to say proportion is greater than 13%.
setwd("D:/Bhoomi/UTD/Academic/Sem-2/MIS - 6356 BA with R/Project/airbnb_classification_r")
#install.packages(c("tidyverse", "caret", "randomForest", "e1071", "rpart", "rpart.plot", "ggplot2", "corrplot", "scales", "DataExplorer"))# Required Libraries
library(tidyverse)
library(caret)
library(randomForest)
library(e1071)
library(rpart)
library(rpart.plot)
library(ggplot2)
library(corrplot)
library(scales)
library(DataExplorer)
library(pROC)  # For ROC curves
# Set seed for reproducibility
set.seed(123)
# Data Loading and Preprocessing
data <- read.csv("D:/Bhoomi/UTD/Academic/Sem-2/MIS - 6356 BA with R/Project/airbnb_classification_r")
#install.packages(c("tidyverse", "caret", "randomForest", "e1071", "rpart", "rpart.plot", "ggplot2", "corrplot", "scales", "DataExplorer"))# Required Libraries
library(tidyverse)
library(caret)
library(randomForest)
library(e1071)
library(rpart)
library(rpart.plot)
library(ggplot2)
library(corrplot)
library(scales)
library(DataExplorer)
library(pROC)  # For ROC curves
# Set seed for reproducibility
set.seed(123)
data <- read.csv("D:/Bhoomi/UTD/Academic/Sem-2/MIS - 6356 BA with R/Project/airbnb_classification_r")
setwd("D:/Bhoomi/UTD/Academic/Sem-2/MIS - 6356 BA with R/Project/airbnb_classification_r/data")
data <- read.csv("D:/Bhoomi/UTD/Academic/Sem-2/MIS - 6356 BA with R/Project/airbnb_classification_r/data")
data <- read.csv("D:/Bhoomi/UTD/Academic/Sem-2/MIS - 6356 BA with R/Project/airbnb_classification_r/data")
data <- read.csv("D:/Bhoomi/UTD/Academic/Sem-2/MIS - 6356 BA with R/Project/airbnb_classification_r/data/airbnb-2.csv")
